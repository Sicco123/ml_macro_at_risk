{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2776f5e1",
   "metadata": {},
   "source": [
    "# Cross-Country Quantile Forecasting with Factor Neural Networks\n",
    "\n",
    "This notebook demonstrates a complete end-to-end workflow for multi-horizon quantile forecasting across countries using Factor Neural Networks (FNN) and Linear Quantile Regression (LQR).\n",
    "\n",
    "## Overview\n",
    "\n",
    "The workflow includes:\n",
    "1. **Data Loading & Exploration**: Load country time series data and explore patterns\n",
    "2. **Data Preprocessing**: Handle missing values, scaling, and create lagged features\n",
    "3. **Model Training**: Train both Factor Neural Networks and Linear Quantile Regression\n",
    "4. **Model Evaluation**: Compare models using quantile loss and Diebold-Mariano tests\n",
    "5. **Visualization**: Create forecast plots, calibration diagrams, and factor analysis\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- **Multi-country analysis** with cross-validation across countries\n",
    "- **Multi-horizon forecasting** (1, 4, 8 periods ahead)\n",
    "- **Quantile regression** for uncertainty quantification\n",
    "- **Factor interpretation** from neural network last layers\n",
    "- **Statistical testing** for model comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658b9325",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Import essential libraries for data processing, modeling, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2036853a",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.12.3)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/home/skooiker/ml_macro_at_risk/.venv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Project imports (adjust paths as needed)\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.utils import (\n",
    "    load_country_data, \n",
    "    load_config,\n",
    "    set_seeds,\n",
    "    handle_missing_values,\n",
    "    scale_features,\n",
    "    create_lagged_features,\n",
    "    create_forecast_targets,\n",
    "    create_time_split\n",
    ")\n",
    "\n",
    "# Import high-level API classes\n",
    "from src.ensemble_nn_api import EnsembleNNAPI  # High-level API from ensemble_nn_api.py\n",
    "from src.lqr_api import LQRModel        # High-level API from lqr_api.py\n",
    "\n",
    "# Alternative: Low-level API (from the packages)\n",
    "\n",
    "from src.metrics import (\n",
    "    pinball_loss,\n",
    "    compute_quantile_losses,\n",
    "    create_loss_summary_table,\n",
    "    dm_test_by_groups,\n",
    "    multiple_testing_correction\n",
    ")\n",
    "\n",
    "from src.evaluation import (\n",
    "    create_model_comparison_table,\n",
    "    plot_training_curves,\n",
    "    plot_forecast_paths,\n",
    "    plot_loss_comparison,\n",
    "    plot_calibration,\n",
    "    create_evaluation_dashboard\n",
    ")\n",
    "\n",
    "import torch \n",
    "torch.set_num_threads(4) \n",
    "\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Numpy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "\n",
    "# print(f\"LQRModel class: {LQRModel}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b3e6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable auto-reload for development\n",
    "# This will automatically reload modules when you change the source code\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Optional: For more verbose reloading info\n",
    "# %autoreload 1  # Only reload modules imported with %aimport\n",
    "# %autoreload 0  # Disable autoreload\n",
    "\n",
    "print(\"Auto-reload enabled: Changes to source files will be automatically reloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c8e3e3",
   "metadata": {},
   "source": [
    "## 2. Configuration and Setup\n",
    "\n",
    "Load configuration and set up the experiment parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c4c6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config_path = \"../configs/experiment_big_data.yaml\"\n",
    "\n",
    "try:\n",
    "    config = load_config(config_path)\n",
    "    print(\"Configuration loaded successfully!\")\n",
    "    print(\"\\nKey parameters:\")\n",
    "    print(f\"Target variable: {config['data']['target']}\")\n",
    "    print(f\"Quantiles: {config['data']['quantiles']}\")\n",
    "    print(f\"Horizons: {config['data']['horizons']}\")\n",
    "    print(f\"Lags: {config['data']['lags']}\")\n",
    "    print(f\"Validation size: {config['splits']['validation_size']}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Configuration file not found at {config_path}\")\n",
    "    print(\"Using default configuration...\")\n",
    "    \n",
    "    # Default configuration\n",
    "    config = {\n",
    "        'seed': 123,\n",
    "        'data': {\n",
    "            'target': 'GDP',\n",
    "            'required_columns': ['TIME', 'CISS', 'INFL_OECD', 'GDP', 'CREDIT_TO_GDP'],\n",
    "            'quantiles': [0.05, 0.95],\n",
    "            'horizons': [1],\n",
    "            'lags': [1],\n",
    "            'missing': 'forward_fill_then_mean',\n",
    "            'scale': 'per_country',\n",
    "            'scale_target': False\n",
    "        },\n",
    "        'splits': {\n",
    "            'validation_size': 0.2,\n",
    "            'train_start': '1990-12-31',\n",
    "            'test_cutoff': '2018-12-31',\n",
    "            'min_train_points': 60\n",
    "        },\n",
    "        'ensemble_nn': {\n",
    "            'units_per_layer': [8, 4],\n",
    "            'activation': 'relu',\n",
    "            'optimizer': 'adam',\n",
    "            'learning_rate': 1e-3,\n",
    "            'epochs': 50,  # Reduced for demo\n",
    "            'batch_size': 64,\n",
    "            'patience': 10,\n",
    "            'parallel_models': 1,  # Single model for demo\n",
    "            'device': 'auto'\n",
    "        },\n",
    "        'lqr': {\n",
    "            'alphas': [0.0, 0.1, 1.0, 10.0],\n",
    "            'solver': 'huberized'\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Set random seed\n",
    "set_seeds(config['seed'])\n",
    "print(f\"\\nRandom seed set to: {config['seed']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58562ed",
   "metadata": {},
   "source": [
    "## 3. Load and Explore Dataset\n",
    "\n",
    "Load country time series data and perform exploratory data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1036bcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load country data\n",
    "data_path = \"../processed_per_country\"\n",
    "\n",
    "try:\n",
    "    # Load all country CSV files\n",
    "    country_data = load_country_data(\n",
    "        data_path=data_path,\n",
    "        required_columns=config['data']['required_columns']\n",
    "    )\n",
    "    \n",
    "    print(f\"Successfully loaded data for {len(country_data)} countries:\")\n",
    "\n",
    "    for country, df in country_data.items():\n",
    "\n",
    "        print(f\"  {country}: {len(df)} observations, {df['TIME'].min()} to {df['TIME'].max()}\")\n",
    "    \n",
    "    # Display first few rows of a sample country\n",
    "    sample_country = list(country_data.keys())[0]\n",
    "    print(f\"\\nSample data from {sample_country}:\")\n",
    "    display(country_data[sample_country].head())\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(f\"\\nSummary statistics for {sample_country}:\")\n",
    "    display(country_data[sample_country].describe())\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"Data directory not found at {data_path}\")\n",
    "    print(\"Creating synthetic data for demonstration...\")\n",
    "    \n",
    "    # Create synthetic data for demonstration\n",
    "    countries = ['USA', 'DEU', 'FRA', 'GBR']\n",
    "    start_date = '2000-01-01'\n",
    "    end_date = '2023-12-31'\n",
    "    freq = 'Q'  # Quarterly data\n",
    "    \n",
    "    country_data = {}\n",
    "    np.random.seed(config['seed'])\n",
    "    \n",
    "    for country in countries:\n",
    "        dates = pd.date_range(start_date, end_date, freq=freq)\n",
    "        n_obs = len(dates)\n",
    "        \n",
    "        # Generate synthetic time series with trends and cycles\n",
    "        t = np.arange(n_obs)\n",
    "        trend = 0.01 * t + np.random.normal(0, 0.1, n_obs).cumsum()\n",
    "        \n",
    "        df = pd.DataFrame({\n",
    "            'TIME': dates,\n",
    "            'GDP': 100 + trend + np.random.normal(0, 2, n_obs),\n",
    "            'CISS': np.random.beta(2, 5, n_obs),\n",
    "            'INFL_OECD': np.random.normal(2, 1, n_obs),\n",
    "            'CREDIT_TO_GDP': 150 + 10 * np.sin(t / 20) + np.random.normal(0, 5, n_obs)\n",
    "        })\n",
    "        \n",
    "        country_data[country] = df\n",
    "    \n",
    "    print(f\"Created synthetic data for {len(country_data)} countries\")\n",
    "    sample_country = countries[0]\n",
    "    print(f\"\\nSample synthetic data from {sample_country}:\")\n",
    "    display(country_data[sample_country].head())\n",
    "\n",
    "# manually put the columns names in the config\n",
    "config['data']['required_columns'] = list(country_data[sample_country].columns)\n",
    "print(f\"\\nUpdated required columns in config: {config['data']['required_columns']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42873ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data\n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "variables = config['data']['required_columns'][1:]  # Exclude 'TIME'\n",
    "colors = plt.cm.Set1(np.linspace(0, 1, len(country_data)))\n",
    "\n",
    "for i, var in enumerate(variables[:6]):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    for j, (country, df) in enumerate(country_data.items()):\n",
    "        ax.plot(df['TIME'], df[var], label=country, color=colors[j], linewidth=2)\n",
    "    \n",
    "    ax.set_title(f'{var} Across Countries')\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel(var)\n",
    "    #ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation analysis\n",
    "print(\"\\nCorrelation analysis:\")\n",
    "for country, df in list(country_data.items())[:2]:  # Show first 2 countries\n",
    "    print(f\"\\n{country} - Correlation matrix:\")\n",
    "    corr_matrix = df[variables].corr()\n",
    "    display(corr_matrix.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db93e7e9",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing\n",
    "\n",
    "Handle missing values, scaling, and create time splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538bc51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Handle missing values\n",
    "print(\"Handling missing values...\")\n",
    "processed_data = handle_missing_values(\n",
    "    country_data, \n",
    "    policy=config['data']['missing']\n",
    ")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values after processing:\")\n",
    "for country, df in processed_data.items():\n",
    "    missing_count = df.isnull().sum().sum()\n",
    "    print(f\"{country}: {missing_count} missing values\")\n",
    "\n",
    "# 2. Create time splits\n",
    "print(\"\\nCreating time splits...\")\n",
    "train_data, test_data, dropped_countries = create_time_split(\n",
    "    processed_data,\n",
    "    train_start=config['splits']['train_start'],\n",
    "    test_cutoff=config['splits']['test_cutoff'],\n",
    "    min_train_points=config['splits']['min_train_points']\n",
    ")\n",
    "\n",
    "print(f\"Train/test split created:\")\n",
    "print(f\"  Training countries: {len(train_data)}\")\n",
    "print(f\"  Test countries: {len(test_data)}\")\n",
    "print(f\"  Dropped countries: {dropped_countries}\")\n",
    "\n",
    "# Show split sizes\n",
    "for country in list(train_data.keys())[:3]:  # First 3 countries\n",
    "    train_size = len(train_data[country])\n",
    "    test_size = len(test_data[country])\n",
    "    print(f\"  {country}: {train_size} train, {test_size} test\")\n",
    "\n",
    "# 3. Scale features (on training data)\n",
    "print(\"\\nScaling features...\")\n",
    "scaled_train, scaled_test, scalers = scale_features(\n",
    "    train_data=train_data,\n",
    "    test_data=test_data,\n",
    "    policy=config['data']['scale'],\n",
    "    target_col=config['data']['target'],\n",
    "    scale_target=config['data']['scale_target'],\n",
    "    trimming=config['data']['trimming'],  # Optional trimming parameter\n",
    ")\n",
    "\n",
    "print(f\"Feature scaling completed using '{config['data']['scale']}' policy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a9b262",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering\n",
    "\n",
    "Create lagged features and forecast targets for multi-horizon prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b80972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create lagged features\n",
    "print(\"Creating lagged features...\")\n",
    "lagged_train = create_lagged_features(\n",
    "    scaled_train, \n",
    "    lags=config['data']['lags']\n",
    ")\n",
    "\n",
    "lagged_test = create_lagged_features(\n",
    "    scaled_test, \n",
    "    lags=config['data']['lags']\n",
    ")\n",
    "\n",
    "# Show example of lagged features\n",
    "sample_country = list(lagged_train.keys())[0]\n",
    "print(f\"\\nLagged features for {sample_country}:\")\n",
    "print(f\"Original columns: {list(scaled_train[sample_country].columns)}\")\n",
    "print(f\"With lags: {list(lagged_train[sample_country].columns)}\")\n",
    "print(f\"Data shape: {lagged_train[sample_country].shape}\")\n",
    "\n",
    "# 2. Create forecast targets\n",
    "print(\"\\nCreating forecast targets...\")\n",
    "target_train = create_forecast_targets(\n",
    "    lagged_train,\n",
    "    target_col=config['data']['target'],\n",
    "    horizons=config['data']['horizons']\n",
    ")\n",
    "\n",
    "target_test = create_forecast_targets(\n",
    "    lagged_test,\n",
    "    target_col=config['data']['target'],\n",
    "    horizons=config['data']['horizons']\n",
    ")\n",
    "\n",
    "# Show target structure\n",
    "target_cols = [f\"{config['data']['target']}_h{h}\" for h in config['data']['horizons']]\n",
    "print(f\"Target columns: {target_cols}\")\n",
    "\n",
    "for country in list(target_train.keys())[:2]:\n",
    "    print(f\"{country} training shape: {target_train[country].shape}\")\n",
    "    print(f\"{country} test shape: {target_test[country].shape}\")\n",
    "\n",
    "# Display sample of processed data\n",
    "print(f\"\\nProcessed data sample from {sample_country}:\")\n",
    "display(target_train[sample_country][['TIME'] + target_cols].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f613ad",
   "metadata": {},
   "source": [
    "## 6. Model Training\n",
    "\n",
    "Train both Factor Neural Networks and Linear Quantile Regression with cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e9e08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummy_variables(data_list, time_col=\"TIME\", add_country_dummies=False):\n",
    "    # for each country in the data list add a country encoding variable \n",
    "    num_of_countries = len(data_list)\n",
    "    if not add_country_dummies:\n",
    "        return data_list\n",
    "    \n",
    "    new_data_list = []\n",
    "\n",
    "    for i,  df in enumerate(data_list):\n",
    "        df_copy = df.copy()\n",
    "        for j in range(num_of_countries):\n",
    "            dummy_col = f'dummy-{j}'\n",
    "            if i != j:\n",
    "                df_copy[dummy_col] = 0\n",
    "            else:\n",
    "                df_copy[dummy_col] = 1\n",
    "        new_data_list.append(df_copy)\n",
    "        \n",
    "    # for i, df in enumerate(data_list):\n",
    "    #     df_copy = df.copy()\n",
    "    #     # Use simple integer encoding instead of one-hot dummies\n",
    "    #     df_copy['country_id'] = i\n",
    "    #     new_data_list.append(df_copy)\n",
    "\n",
    "\n",
    "    \n",
    "    return new_data_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bc4b51",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c30b15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for models\n",
    "# Convert country dictionaries to lists for model APIs\n",
    "import traceback\n",
    "from src.ensemble_nn_api import EnsembleNNAPI  # High-level API from ensemble_nn_api.py\n",
    "from src.lqr_api import LQRModel        # High-level API from lqr_api.py\n",
    "\n",
    "train_data_list = []\n",
    "test_data_list = []\n",
    "\n",
    "for country, df in scaled_train.items():\n",
    "    df_copy = df.copy()\n",
    "    #df_copy['country'] = country\n",
    "    train_data_list.append(df_copy)\n",
    "\n",
    "for country, df in scaled_test.items():\n",
    "    df_copy = df.copy()\n",
    "    #df_copy['country'] = country\n",
    "    test_data_list.append(df_copy)\n",
    "\n",
    "print(f\"Prepared data for {len(train_data_list)} countries\")\n",
    "\n",
    "# Ensure all data types are proper (TIME should be datetime, others numeric)\n",
    "for i, df in enumerate(train_data_list):\n",
    "    if 'TIME' in df.columns and df['TIME'].dtype == 'object':\n",
    "        train_data_list[i]['TIME'] = pd.to_datetime(df['TIME'])\n",
    "            \n",
    "for i, df in enumerate(test_data_list):\n",
    "    if 'TIME' in df.columns and df['TIME'].dtype == 'object':\n",
    "        test_data_list[i]['TIME'] = pd.to_datetime(df['TIME'])\n",
    "\n",
    "\n",
    "if config['ensemble_nn']['country_dummies'] and not config['ensemble_nn']['per_country']:\n",
    "    global_train_data_list = create_dummy_variables(\n",
    "        train_data_list,\n",
    "        time_col=\"TIME\",\n",
    "        add_country_dummies=config['ensemble_nn']['country_dummies']\n",
    "    )\n",
    "    \n",
    "    global_test_data_list = create_dummy_variables(\n",
    "        test_data_list,\n",
    "        time_col=\"TIME\",\n",
    "        add_country_dummies=config['ensemble_nn']['country_dummies']\n",
    "    )\n",
    "else:\n",
    "    global_train_data_list = train_data_list\n",
    "    global_test_data_list = test_data_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689c0d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# === Train Factor Neural Network ===\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Training Factor Neural Network\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Determine optimal k_folds based on available countries\n",
    "\n",
    "n_countries = len(train_data_list)\n",
    "\n",
    "print(f\"Available countries: {n_countries}\")\n",
    "\n",
    "country_names = [country for country in list(target_train.keys())]\n",
    "\n",
    "if config['ensemble_nn']['per_country']:\n",
    "    fnn_models = {}\n",
    "    for i, df in enumerate(train_data_list):\n",
    "       \n",
    "        print(f\"Training Factor NN for {i}...\")\n",
    "\n",
    "        ensemble_nn = EnsembleNNAPI(\n",
    "            data_list=[df],\n",
    "            target=config['data']['target'],\n",
    "            quantiles=config['data']['quantiles'],\n",
    "            forecast_horizons=config['data']['horizons'],\n",
    "            units_per_layer=config['ensemble_nn']['units_per_layer'],\n",
    "            lags=config['data']['lags'],\n",
    "            activation=config['ensemble_nn']['activation'],\n",
    "            device=config['ensemble_nn']['device'],\n",
    "            seed=config['seed'], \n",
    "            transform=True,  # Enable data transformation\n",
    "        )\n",
    "    \n",
    "        ensemble_results = ensemble_nn.fit(\n",
    "            epochs=config['ensemble_nn']['epochs'],\n",
    "            learning_rate=config['ensemble_nn']['learning_rate'],\n",
    "            batch_size=config['ensemble_nn']['batch_size'],\n",
    "            validation_size=config['splits']['validation_size'],  # Use adjusted k_folds\n",
    "            patience=config['ensemble_nn']['patience'],\n",
    "            verbose=1,\n",
    "            optimizer=config['ensemble_nn']['optimizer'],\n",
    "            parallel_models=config['ensemble_nn']['parallel_models'],\n",
    "            l2=config['ensemble_nn']['l2_penalty'],\n",
    "            return_validation_loss=True,\n",
    "            return_train_loss=True,\n",
    "            shuffle=True\n",
    "        )\n",
    "\n",
    "        print(f\"✓ Factor NN for {i} trained successfully!\")\n",
    "\n",
    "        # Store model and results\n",
    "        fnn_models[i] = {\n",
    "            'model': ensemble_nn,\n",
    "            'results': ensemble_results\n",
    "        }\n",
    "        \n",
    "         # Plot training curves if available\n",
    "        if 'train_losses' in ensemble_results and 'val_losses' in ensemble_results:\n",
    "            plot_training_curves(\n",
    "                ensemble_results['train_losses'][min(config['ensemble_nn']['patience']-1,5):],\n",
    "                ensemble_results['val_losses'][min(config['ensemble_nn']['patience']-1,5):],\n",
    "                title=\"Factor NN Training Curves\"\n",
    "            )\n",
    "            plt.show()\n",
    "    \n",
    "    print(f\"\\nTrained Factor NN models for {len(fnn_models)} countries.\")\n",
    "else:\n",
    "\n",
    "  \n",
    "    # Initialize Ensemble NN using high-level API\n",
    "    ensemble_nn = EnsembleNNAPI(\n",
    "        data_list=global_train_data_list,\n",
    "        target=config['data']['target'],\n",
    "        quantiles=config['data']['quantiles'],\n",
    "        forecast_horizons=config['data']['horizons'],\n",
    "        units_per_layer=config['ensemble_nn']['units_per_layer'],\n",
    "        lags=config['data']['lags'],\n",
    "        activation=config['ensemble_nn']['activation'],\n",
    "        device=config['ensemble_nn']['device'],\n",
    "        seed=config['seed'], \n",
    "        transform=True,  # Enable data transformation\n",
    "        prefit_AR=True,  # Enable pre-fitting of AR models\n",
    "        country_ids=country_names,  # Use country names\n",
    "        time_col=\"TIME\",\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    print(f\"✓ Ensemble NN initialized successfully!\")\n",
    "    print(f\"  Input dimension: {ensemble_nn.input_dim}\")\n",
    "    print(f\"  Target quantiles: {ensemble_nn.quantiles}\")\n",
    "    print(f\"  Forecast horizons: {ensemble_nn.forecast_horizons}\")\n",
    "\n",
    "    # Train with cross-validation\n",
    "    print(\"\\nStarting training with cross-validation...\")\n",
    "    ensemble_results = ensemble_nn.fit(\n",
    "        epochs=config['ensemble_nn']['epochs'],\n",
    "        learning_rate=config['ensemble_nn']['learning_rate'],\n",
    "        batch_size=config['ensemble_nn']['batch_size'],\n",
    "        validation_size=config['splits']['validation_size'],  # Use adjusted k_folds\n",
    "        patience=config['ensemble_nn']['patience'],\n",
    "        verbose=1,\n",
    "        optimizer=config['ensemble_nn']['optimizer'],\n",
    "        parallel_models=config['ensemble_nn']['parallel_models'],\n",
    "        l2=config['ensemble_nn']['l2_penalty'],\n",
    "        return_validation_loss=True,\n",
    "        return_train_loss=True,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    print(\"\\n✓ Ensemble NN training completed successfully!\")\n",
    "    print(f\"  Results keys: {list(ensemble_results.keys())}\")\n",
    "    print(f\"  Number of parameters: {ensemble_results.get('n_parameters', 'Unknown')}\")\n",
    "    print(f\"  Final validation loss: {ensemble_results.get('final_val_loss', 'Unknown')}\")\n",
    "\n",
    "    # Plot training curves if available\n",
    "    if 'train_losses' in ensemble_results and 'val_losses' in ensemble_results:\n",
    "        plot_training_curves(\n",
    "            ensemble_results['train_losses'],#[min(config['ensemble_nn']['patience']-1,5):],\n",
    "            ensemble_results['val_losses'],#[min(config['ensemble_nn']['patience']-1,5):],\n",
    "            title=\"Ensemble NN Training Curves\"\n",
    "        )\n",
    "        plt.show()\n",
    "    \n",
    "    # Mark as successfully trained\n",
    "    fnn_training_successful = True\n",
    "        \n",
    "   \n",
    "    # === Status Summary ===\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"TRAINING STATUS SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"✓ Data preprocessing: SUCCESSFUL\")\n",
    "    print(f\"✓ Feature engineering: SUCCESSFUL\") \n",
    "    print(f\"✓ Dataset creation: SUCCESSFUL\")\n",
    "    print(f\"✓ Data type handling: SUCCESSFUL (fixed object dtype issue)\")\n",
    "    print(f\"{'✓' if fnn_training_successful else '🚨'} Factor NN training: {'SUCCESSFUL' if fnn_training_successful else 'FAILED (cross-validation issue)'}\")\n",
    "\n",
    "    if not fnn_training_successful:\n",
    "        print(f\"\\nNote: The core infrastructure is working correctly.\")\n",
    "        print(f\"The training failure is due to cross-validation configuration,\")\n",
    "        print(f\"not fundamental data type or model implementation issues.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f48421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Train Linear Quantile Regression ===\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Training Linear Quantile Regression\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "try:\n",
    "    # Initialize LQR using high-level API\n",
    "    lqr_model = LQRModel(\n",
    "        data_list=train_data_list,\n",
    "        target=config['data']['target'],\n",
    "        quantiles=config['data']['quantiles'],\n",
    "        forecast_horizons=config['data']['horizons'],\n",
    "        lags=config['data']['lags'],\n",
    "        alpha=1.0,  # Will be cross-validated\n",
    "        fit_intercept=True,\n",
    "        solver=config['lqr']['solver'],\n",
    "        seed=config['seed']\n",
    "    )\n",
    "    \n",
    "    print(f\"LQR initialized\")\n",
    "    \n",
    "    # Cross-validate regularization parameter\n",
    "    print(\"Cross-validating regularization parameter...\")\n",
    "    best_alpha = lqr_model.validate_alpha(\n",
    "        alphas=config['lqr']['alphas'],\n",
    "        validation_size=config['splits']['validation_size']\n",
    "    )\n",
    "    \n",
    "    print(f\"Best alpha: {best_alpha}\")\n",
    "    \n",
    "    # Fit final model\n",
    "    print(\"Fitting final model...\")\n",
    "    lqr_coefficients = lqr_model.fit()\n",
    "    \n",
    "    print(\"LQR training completed!\")\n",
    "\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"LQR training failed: {e}\")\n",
    "    print(f\"Error type: {type(e).__name__}\")\n",
    "    print(f\"Error location:\")\n",
    "    traceback.print_exc()\n",
    "    print(\"This might be due to missing dependencies. Continuing with synthetic model results...\")\n",
    "    lqr_model = None\n",
    "    lqr_coefficients = None\n",
    "\n",
    "print(\"\\nModel training phase completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2710e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### lqr per country\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"LQR Coefficients by Country\")\n",
    "print(\"=\"*50)\n",
    "lqr_models = {}\n",
    "\n",
    "for i, data in enumerate(train_data_list):\n",
    "    # Initialize LQR using high-level API\n",
    "    if i == 0:\n",
    "        print(data.head())\n",
    "    lqr_model = LQRModel(\n",
    "        data_list=[data],\n",
    "        target=config['data']['target'],\n",
    "        quantiles=config['data']['quantiles'],\n",
    "        forecast_horizons=config['data']['horizons'],\n",
    "        lags=config['data']['lags'],\n",
    "        alpha=1.0,  # Will be cross-validated\n",
    "        fit_intercept=True,\n",
    "        solver=config['lqr']['solver'],\n",
    "        seed=config['seed']\n",
    "    )\n",
    "\n",
    "    \n",
    "    # Cross-validate regularization parameter\n",
    "    # Cross-validate regularization parameter\n",
    "    best_alpha = lqr_model.k_fold_validation(alphas = config['lqr']['alphas'],\n",
    "        n_splits=10\n",
    "    )\n",
    "    \n",
    "    print(f\"Best alpha for country {countries[i]}: {best_alpha}\")\n",
    "    \n",
    "    # Fit final model\n",
    "    lqr_coefficients = lqr_model.fit()\n",
    "    \n",
    "\n",
    "    lqr_models[i] = {\n",
    "        'model': lqr_model,\n",
    "        'coefficients': lqr_coefficients\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a2b69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### lqr per country\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"LQR Coefficients by Country\")\n",
    "print(\"=\"*50)\n",
    "lqr_ar_models = {}\n",
    "\n",
    "for i, data in enumerate(train_data_list):\n",
    "    # Initialize LQR using high-level API\n",
    "    if i == 0:\n",
    "        print(data.head())\n",
    "    \n",
    "    # only use the target column and the time column\n",
    "    data_temp = data[['TIME', config['data']['target']]].copy()\n",
    "\n",
    "    lqr_model = LQRModel(\n",
    "        data_list=[data_temp],\n",
    "        target=config['data']['target'],\n",
    "        quantiles=config['data']['quantiles'],\n",
    "        forecast_horizons=config['data']['horizons'],\n",
    "        lags=config['data']['lags'],\n",
    "        alpha=0.0,  # Will be cross-validated\n",
    "        fit_intercept=True,\n",
    "        solver=config['lqr']['solver'],\n",
    "        seed=config['seed']\n",
    "    )\n",
    "\n",
    "    \n",
    "    # Cross-validate regularization parameter\n",
    "    # Cross-validate regularization parameter\n",
    "    # best_alpha = lqr_model.k_fold_validation(alphas = config['lqr']['alphas'],\n",
    "    #     n_splits=10\n",
    "    # )\n",
    "    \n",
    "    #print(f\"Best alpha for country {i}: {best_alpha}\")\n",
    "    \n",
    "    # Fit final model\n",
    "    lqr_coefficients = lqr_model.fit()\n",
    "    \n",
    "\n",
    "    lqr_ar_models[i] = {\n",
    "        'model': lqr_model,\n",
    "        'coefficients': lqr_coefficients\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4606a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def normalize(upb, unb, data):\n",
    "#     # normalize per column \n",
    "#     return (data - data.min()) / (data.max() - data.min()) * (upb - unb) + unb\n",
    "\n",
    "\n",
    "# def add_random_fourier_features(data, target, n_features=10, seed=42):\n",
    "    \n",
    "#     np.random.seed(seed)\n",
    "    \n",
    "#     # Generate random weights and biases\n",
    "#     weights = np.random.randn(n_features, data.shape[1] - 1)  # Exclude TIME column\n",
    "#     biases = np.random.uniform(0, 2 * np.pi, n_features)\n",
    "\n",
    "#     target_data = data[target]\n",
    "#     # drop target from data \n",
    "\n",
    "    \n",
    "#     new_data = pd.DataFrame()\n",
    "\n",
    "#     # Create new features - both sin and cos for each random projection\n",
    "#     for i in range(n_features):\n",
    "#         projection = np.dot(data.iloc[:, 1:].values , weights[i]) + biases[i]\n",
    "#         # Add both sin and cos features\n",
    "#         new_data[f'rff_cos_{i}'] = np.cos(projection)\n",
    "#         new_data[f'rff_sin_{i}'] = np.sin(projection)\n",
    "\n",
    "#     new_data[target] = target_data\n",
    "\n",
    "#     return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ead2df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### lqr per country\n",
    "# print(\"\\n\" + \"=\"*50)\n",
    "# print(\"LQR Coefficients by Country\")\n",
    "# print(\"=\"*50)\n",
    "# rff_lqr_models = {}\n",
    "\n",
    "# for i, data in enumerate(train_data_list):\n",
    "\n",
    "#     # add random fourier features to data \n",
    "#     data = add_random_fourier_features(data, target=config['data']['target'], n_features=config['lqr']['rff_features'], seed=config['seed'])\n",
    "    \n",
    "#     # print dimensions of data\n",
    "#     print(f\"Data shape for country {i}: {data.shape}\")\n",
    "#     # Initialize LQR using high-level API\n",
    "#     lqr_model = LQRModel(\n",
    "#         data_list=[data],\n",
    "#         target=config['data']['target'],\n",
    "#         quantiles=config['data']['quantiles'],\n",
    "#         forecast_horizons=config['data']['horizons'],\n",
    "#         lags=config['data']['lags'],\n",
    "#         alpha=1.0,  # Will be cross-validated\n",
    "#         fit_intercept=True,\n",
    "#         solver=config['lqr']['solver'],\n",
    "#         seed=config['seed']\n",
    "#     )\n",
    "\n",
    "    \n",
    "#     # Cross-validate regularization parameter\n",
    "#     best_alpha = lqr_model.k_fold_validation(alphas = config['lqr']['alphas'],\n",
    "#         n_splits=10\n",
    "#     )\n",
    "    \n",
    "#     print(f\"Best alpha for country {i}: {best_alpha}\"   )\n",
    "#     # Fit final model\n",
    "#     lqr_coefficients = lqr_model.fit()\n",
    "    \n",
    "\n",
    "#     rff_lqr_models[i] = {\n",
    "#         'model': lqr_model,\n",
    "#         'coefficients': lqr_coefficients\n",
    "#     }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9a2f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lqr_per_country_predictions, lqr_per_country_targets = {}, {}\n",
    "country_names = [country for country in list(target_train.keys())]\n",
    "for idx, test_data in enumerate(test_data_list):\n",
    "    model = lqr_models[idx]['model']\n",
    "    predictions, targets = model.predict([test_data])\n",
    "    lqr_per_country_predictions[country_names[idx]] = predictions\n",
    "    lqr_per_country_targets[country_names[idx]] = targets\n",
    "\n",
    "lqr_ar_per_country_predictions, lqr_ar_per_country_targets = {}, {}\n",
    "\n",
    "for idx, test_data in enumerate(test_data_list):\n",
    "    model = lqr_ar_models[idx]['model']\n",
    "    predictions, targets = model.predict([test_data[['TIME', config['data']['target']]]])\n",
    "    lqr_ar_per_country_predictions[country_names[idx]] = predictions\n",
    "    lqr_ar_per_country_targets[country_names[idx]] = targets\n",
    "\n",
    "print(f\"Number of countries with LQR predictions: {len(lqr_per_country_predictions)}\")\n",
    "print(f\"Number of countries with LQR AR predictions: {len(lqr_ar_per_country_predictions)}\")\n",
    "\n",
    "fnn_per_country_predictions, fnn_per_country_targets = {}, {}\n",
    "\n",
    "for idx, test_data in enumerate(global_test_data_list):\n",
    "\n",
    "    if config['ensemble_nn']['per_country']:\n",
    "        model = fnn_models[idx]['model']\n",
    "        predictions, targets = model.predict_per_country(test_data, \"COUNTRY_000\")\n",
    "        fnn_per_country_predictions[country_names[idx]] = predictions\n",
    "        fnn_per_country_targets[country_names[idx]] = targets\n",
    "    else:\n",
    "        if ensemble_nn:\n",
    "            predictions, targets = ensemble_nn.predict_per_country(test_data, country_names[idx])\n",
    "  \n",
    "            fnn_per_country_predictions[country_names[idx]] = predictions\n",
    "            fnn_per_country_targets[country_names[idx]] = targets\n",
    "        else:\n",
    "            fnn_per_country_predictions[country_names[idx]] = None\n",
    "            fnn_per_country_targets[country_names[idx]] = None\n",
    "\n",
    "print(f\"FNN predictions: {len(fnn_per_country_predictions)} countries\")\n",
    "print(f\"LQR predictions: {len(lqr_per_country_predictions)} countries\")\n",
    "\n",
    "# print(lqr_per_country_targets[\"HUN\"][:,0])\n",
    "# print(fnn_per_country_targets[\"HUN\"][:,0])\n",
    "\n",
    "# rff_per_country_predictions, rff_per_country_targets = {}, {}\n",
    "\n",
    "# for idx, test_data in enumerate(test_data_list):\n",
    "#     model = rff_lqr_models[idx]['model']\n",
    "#     test_data = add_random_fourier_features(test_data, n_features=config['lqr']['rff_features'], seed=config['seed'])\n",
    "#     predictions, targets = model.predict([test_data])\n",
    "#     rff_per_country_predictions[country_names[idx]] = predictions\n",
    "#     rff_per_country_targets[country_names[idx]] = targets\n",
    "\n",
    "\n",
    "fnn_per_country_predictions = lqr_ar_per_country_predictions\n",
    "nn_per_country_targets = lqr_ar_per_country_targets\n",
    "# lqr_per_country_predictions = lqr_ar_per_country_predictions\n",
    "# lqr_per_country_targets = lqr_ar_per_country_targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc8cc7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56cc586c",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation\n",
    "\n",
    "Now let's evaluate our trained FNN model and make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038c047e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21715c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnn_predictions, fnn_targets = ensemble_nn.predict(global_test_data_list) if ensemble_nn else (None, None)\n",
    "#lqr_predictions, lqr_targets = lqr_model.predict(test_data_list) if lqr_model else (None, None)\n",
    "#print(lqr_predictions )\n",
    "# #lqr_predictions, lqr_targets = lqr_per_country_predictions, lqr_per_country_targets\n",
    "\n",
    "# print(fnn_targets.shape, lqr_targets.shape)\n",
    "\n",
    "# # === Evaluate Models ===\n",
    "# print(\"\\n\" + \"=\"*50)\n",
    "# print(\"MODEL EVALUATION\")\n",
    "# print(\"=\"*50)\n",
    "\n",
    "# # Display prediction shapes for understanding\n",
    "# if fnn_predictions is not None:\n",
    "#     print(f\"FNN predictions shape: {fnn_predictions.shape}\")\n",
    "#     print(f\"  - Dimension 0 (samples): {fnn_predictions.shape[0]} stacked across all countries\")\n",
    "#     print(f\"  - Dimension 1 (quantiles): {fnn_predictions.shape[1]} quantiles\")\n",
    "#     print(f\"  - Dimension 2 (horizons): {fnn_predictions.shape[2]} horizons\")\n",
    "\n",
    "# if lqr_predictions is not None:\n",
    "#     print(f\"LQR predictions shape: {lqr_predictions.shape}\")\n",
    "\n",
    "# if fnn_targets is not None:\n",
    "#     print(f\"FNN targets shape: {fnn_targets.shape}\")\n",
    "#     print(f\"  - Dimension 0 (samples): {fnn_targets.shape[0]} stacked across all countries\")\n",
    "#     print(f\"  - Dimension 1 (horizons): {fnn_targets.shape[1]} horizons\")\n",
    "\n",
    "# # Create synthetic predictions for demonstration if models failed\n",
    "# if fnn_predictions is None and lqr_predictions is None:\n",
    "#     print(\"Creating synthetic predictions for demonstration...\")\n",
    "    \n",
    "#     # Generate synthetic predictions with realistic patterns\n",
    "#     np.random.seed(config['seed'])\n",
    "#     n_test_points = sum(len(df) for df in test_data_list)\n",
    "#     n_quantiles = len(config['data']['quantiles'])\n",
    "#     n_horizons = len(config['data']['horizons'])\n",
    "    \n",
    "#     # Create 3D arrays: (samples, quantiles, horizons)\n",
    "#     fnn_predictions = np.random.normal(0, 1, (n_test_points, n_quantiles, n_horizons))\n",
    "#     lqr_predictions = np.random.normal(0, 1.2, (n_test_points, n_quantiles, n_horizons))\n",
    "    \n",
    "#     # Create 2D targets: (samples, horizons)\n",
    "#     fnn_targets = lqr_targets = np.random.normal(0, 1, (n_test_points, n_horizons))\n",
    "    \n",
    "#     print(\"✓ Synthetic predictions created for evaluation demonstration\")\n",
    "\n",
    "# # === 1. Compute Tick Loss (Quantile Loss) ===\n",
    "# print(\"\\n1. Computing Tick Loss for all quantiles and horizons...\")\n",
    "\n",
    "# from src.metrics import pinball_loss\n",
    "\n",
    "# tick_losses = {'FNN': {}, 'LQR': {}}\n",
    "\n",
    "# # Calculate tick losses for each horizon and quantile\n",
    "# for h, horizon in enumerate(config['data']['horizons']):\n",
    "#     print(f\"\\nHorizon {horizon} (index {h}):\")\n",
    "#     tick_losses['FNN'][horizon] = {}\n",
    "#     tick_losses['LQR'][horizon] = {}\n",
    "    \n",
    "#     # Get targets for this horizon\n",
    "#     # If targets is 2D: (samples, horizons), get column h\n",
    "#     # If targets is 1D and only one horizon, use as-is\n",
    "#     if fnn_targets.ndim == 2:\n",
    "#         actual = fnn_targets[:, h]\n",
    "#     else:\n",
    "#         actual = fnn_targets  # Single horizon case\n",
    "    \n",
    "#     for q, quantile in enumerate(config['data']['quantiles']):\n",
    "#         # FNN tick loss: get predictions for quantile q, horizon h\n",
    "#         if fnn_predictions is not None:\n",
    "#             fnn_pred = fnn_predictions[:, q, h]  # (samples,)\n",
    "#             fnn_loss = pinball_loss(\n",
    "#                 y_true=actual,\n",
    "#                 y_pred=fnn_pred,\n",
    "#                 quantile=quantile\n",
    "#             )\n",
    "#             tick_losses['FNN'][horizon][quantile] = np.mean(fnn_loss)\n",
    "        \n",
    "#         # LQR tick loss: get predictions for quantile q, horizon h\n",
    "#         if lqr_predictions is not None:\n",
    "#             lqr_pred = lqr_predictions[:, q, h]  # (samples,)\n",
    "#             lqr_loss = pinball_loss(\n",
    "#                 y_true=actual,\n",
    "#                 y_pred=lqr_pred,\n",
    "#                 quantile=quantile\n",
    "#             )\n",
    "#             tick_losses['LQR'][horizon][quantile] = np.mean(lqr_loss)\n",
    "        \n",
    "    \n",
    "\n",
    "# # === 2. Create Tick Loss Comparison Table ===\n",
    "# print(\"\\n2. Creating tick loss comparison table...\")\n",
    "\n",
    "# # Prepare data for comparison table\n",
    "# comparison_data = []\n",
    "# for horizon in config['data']['horizons']:\n",
    "#     for quantile in config['data']['quantiles']:\n",
    "#         fnn_loss = tick_losses['FNN'][horizon][quantile]\n",
    "#         lqr_loss = tick_losses['LQR'][horizon][quantile]\n",
    "#         improvement = ((lqr_loss - fnn_loss) / lqr_loss) * 100  # % improvement of FNN over LQR\n",
    "#         print(fnn_loss, lqr_loss, improvement)\n",
    "#         comparison_data.append({\n",
    "#             'Horizon': horizon,\n",
    "#             'Quantile': quantile,\n",
    "#             'FNN_Loss': fnn_loss,\n",
    "#             'LQR_Loss': lqr_loss,\n",
    "#             'Improvement_%': improvement,\n",
    "#             'Better_Model': 'FNN' if fnn_loss < lqr_loss else 'LQR'\n",
    "#         })\n",
    "\n",
    "# comparison_df = pd.DataFrame(comparison_data)\n",
    "# print(\"\\nTick Loss Comparison Table:\")\n",
    "# display(comparison_df.round(4))\n",
    "\n",
    "# # === 3. Visualization: Tick Loss Comparison ===\n",
    "# print(\"\\n3. Creating tick loss comparison plots...\")\n",
    "\n",
    "# # Plot 1: Tick Loss by Quantile and Horizon\n",
    "# fig, axes = plt.subplots(1, len(config['data']['horizons']), figsize=(5*len(config['data']['horizons']), 6))\n",
    "# if len(config['data']['horizons']) == 1:\n",
    "#     axes = [axes]\n",
    "\n",
    "# for i, horizon in enumerate(config['data']['horizons']):\n",
    "#     ax = axes[i]\n",
    "    \n",
    "#     quantiles = config['data']['quantiles']\n",
    "#     fnn_losses = [tick_losses['FNN'][horizon][q] for q in quantiles]\n",
    "#     lqr_losses = [tick_losses['LQR'][horizon][q] for q in quantiles]\n",
    "    \n",
    "#     x = np.arange(len(quantiles))\n",
    "#     width = 0.35\n",
    "    \n",
    "#     bars1 = ax.bar(x - width/2, fnn_losses, width, label='Factor NN', alpha=0.8, color='skyblue')\n",
    "#     bars2 = ax.bar(x + width/2, lqr_losses, width, label='LQR', alpha=0.8, color='lightcoral')\n",
    "    \n",
    "#     ax.set_xlabel('Quantiles')\n",
    "#     ax.set_ylabel('Tick Loss')\n",
    "#     ax.set_title(f'Tick Loss Comparison - Horizon {horizon}')\n",
    "#     ax.set_xticks(x)\n",
    "#     ax.set_xticklabels([f'{q:.2f}' for q in quantiles])\n",
    "#     ax.legend()\n",
    "#     ax.grid(True, alpha=0.3)\n",
    "    \n",
    "#     # Add value labels on bars\n",
    "#     for bar in bars1:\n",
    "#         height = bar.get_height()\n",
    "#         ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "#                 f'{height:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "#     for bar in bars2:\n",
    "#         height = bar.get_height()\n",
    "#         ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "#                 f'{height:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# #\n",
    "# # === 5. Summary Statistics ===\n",
    "# print(\"\\n5. Summary statistics...\")\n",
    "\n",
    "# overall_stats = {\n",
    "#     'FNN_avg_loss': np.mean([loss for horizon_dict in tick_losses['FNN'].values() \n",
    "#                             for loss in horizon_dict.values()]),\n",
    "#     'LQR_avg_loss': np.mean([loss for horizon_dict in tick_losses['LQR'].values() \n",
    "#                             for loss in horizon_dict.values()]),\n",
    "#     'FNN_wins': sum(1 for _, row in comparison_df.iterrows() if row['Better_Model'] == 'FNN'),\n",
    "#     'LQR_wins': sum(1 for _, row in comparison_df.iterrows() if row['Better_Model'] == 'LQR'),\n",
    "#     'avg_improvement': comparison_df['Improvement_%'].mean()\n",
    "# }\n",
    "\n",
    "# print(f\"\\nOverall Performance Summary:\")\n",
    "# print(f\"  Average FNN Loss: {overall_stats['FNN_avg_loss']:.4f}\")\n",
    "# print(f\"  Average LQR Loss: {overall_stats['LQR_avg_loss']:.4f}\")\n",
    "# print(f\"  FNN wins: {overall_stats['FNN_wins']}/{len(comparison_df)} cases\")\n",
    "# print(f\"  LQR wins: {overall_stats['LQR_wins']}/{len(comparison_df)} cases\")\n",
    "# print(f\"  Average improvement: {overall_stats['avg_improvement']:.2f}%\")\n",
    "\n",
    "# print(\"\\n✓ Tick loss evaluation completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40771e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 6. Forecast Visualization ===\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FORECAST VISUALIZATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Plot forecast paths for each country and horizon\n",
    "countries = list(scaled_test.keys())\n",
    "n_countries_to_plot = len(countries)  # Plot first 4 countrie\n",
    "# divide by 2 and round up for subplots\n",
    "div_2 = (n_countries_to_plot + 1) // 2\n",
    "\n",
    "\n",
    "# Calculate country boundaries for indexing into stacked arrays\n",
    "country_boundaries = [0]\n",
    "for df in test_data_list:\n",
    "    country_boundaries.append(country_boundaries[-1] + len(df))\n",
    "\n",
    "for h, horizon in enumerate(config['data']['horizons']):\n",
    "    fig, axes = plt.subplots(div_2, 2, figsize=(15, 30))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    print(f\"\\nCreating forecast plots for horizon {horizon}...\")\n",
    "    \n",
    "    for i, country in enumerate(countries[:n_countries_to_plot]):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Get country data boundaries\n",
    "        start_idx = country_boundaries[i]\n",
    "        end_idx = country_boundaries[i + 1]\n",
    "        \n",
    "        # Extract predictions and targets for this country and horizon\n",
    "        # Targets: if 2D (samples, horizons), get column h; if 1D, use as-is\n",
    "        if fnn_per_country_targets[country].ndim == 2:\n",
    "            actual = fnn_per_country_targets[country][:, h]\n",
    "        else:\n",
    "            actual = fnn_per_country_targets[country]  # Single horizon case\n",
    "        \n",
    "        # Predictions: (samples, quantiles, horizons) -> get [:, :, h] for this horizon\n",
    "        fnn_pred_this_horizon = fnn_per_country_predictions[country][:, h]  # (country_samples, quantiles)\n",
    "        lqr_pred_this_horizon = lqr_per_country_predictions[country][:, h]  # (country_samples, quantiles)\n",
    "        lqr_ar_pred_this_horizon = lqr_ar_per_country_predictions[country][:, h]  # (country_samples, quantiles)\n",
    "\n",
    "        # Extract quantiles (assuming first is lower, second is upper)\n",
    "        try:\n",
    "            fnn_pred_q05 = fnn_pred_this_horizon[:, 0]  # Lower quantile\n",
    "            fnn_pred_q95 = fnn_pred_this_horizon[:, 1]  # Upper quantile\n",
    "            lqr_pred_q05 = lqr_pred_this_horizon[:, 0]\n",
    "            lqr_pred_q95 = lqr_pred_this_horizon[:, 1]\n",
    "            lqr_ar_pred_q05 = lqr_ar_pred_this_horizon[:, 0]\n",
    "            lqr_ar_pred_q95 = lqr_ar_pred_this_horizon[:, 1]\n",
    "        except IndexError:\n",
    "            fnn_pred_q05 = [np.nan] * len(actual)\n",
    "            fnn_pred_q95 = [np.nan] * len(actual)\n",
    "            lqr_pred_q05 = [np.nan] * len(actual)\n",
    "            lqr_pred_q95 = [np.nan] * len(actual)\n",
    "            lqr_ar_pred_q05 = [np.nan] * len(actual)\n",
    "            lqr_ar_pred_q95 = [np.nan] * len(actual)\n",
    "\n",
    "            \n",
    "        # Time index for plotting\n",
    "        time_idx = range(len(actual))\n",
    "        \n",
    "        # Plot actual values\n",
    "        ax.plot(time_idx, actual, 'k-', linewidth=2, label='Actual', alpha=0.8)\n",
    "        \n",
    "        # Plot FNN predictions with uncertainty band\n",
    "        ax.fill_between(time_idx, fnn_pred_q05, fnn_pred_q95, \n",
    "                       alpha=0.3, color='blue', label='FNN 90% CI')\n",
    "        ax.plot(time_idx, fnn_pred_this_horizon, 'b--', \n",
    "               linewidth=1.5, label='FNN Median', alpha=0.8)\n",
    "        \n",
    "        # Plot LQR predictions with uncertainty band  \n",
    "        ax.fill_between(time_idx, lqr_pred_q05, lqr_pred_q95, \n",
    "                       alpha=0.2, color='red', label='LQR 90% CI')\n",
    "        ax.plot(time_idx, lqr_pred_this_horizon, 'r:', \n",
    "               linewidth=1.5, label='LQR Median', alpha=0.8)\n",
    "        \n",
    "        # Plot LQR AR predictions with uncertainty band\n",
    "        ax.fill_between(time_idx, lqr_ar_pred_q05, lqr_ar_pred_q95, \n",
    "                       alpha=0.2, color='green', label='LQR AR 90% CI')\n",
    "        ax.plot(time_idx, lqr_ar_pred_this_horizon, 'g-.', \n",
    "               linewidth=1.5, label='LQR AR Median', alpha=0.8)\n",
    "        \n",
    "        ax.set_title(f'{country} - Horizon {horizon}')\n",
    "        ax.set_xlabel('Time Period')\n",
    "        ax.set_ylabel(config['data']['target'])\n",
    "        ax.legend(fontsize=8)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle(f'Forecast Comparison - {horizon}-Period Ahead', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# # === 7. Quantile Coverage Analysis ===\n",
    "# print(\"\\n7. Quantile coverage analysis...\")\n",
    "\n",
    "# # Check if actual values fall within prediction intervals\n",
    "# coverage_stats = {}\n",
    "\n",
    "# for h, horizon in enumerate(config['data']['horizons']):\n",
    "#     coverage_stats[horizon] = {}\n",
    "    \n",
    "#     # Get targets for this horizon\n",
    "#     if fnn_targets.ndim == 2:\n",
    "#         actual = fnn_targets[:, h]\n",
    "#     else:\n",
    "#         actual = fnn_targets\n",
    "    \n",
    "#     # For each model\n",
    "#     for model_name, predictions in [('FNN', fnn_per_country_predictions), ('LQR', lqr_per_country_predictions)]:\n",
    "#         # Get predictions for this horizon: (samples, quantiles)\n",
    "#         preds_this_horizon = predictions[:, :, h]\n",
    "        \n",
    "#         coverage_stats[horizon][model_name] = {}\n",
    "#         for q, quantile in enumerate(config['data']['quantiles']):\n",
    "#             # Get lower and upper quantiles\n",
    "#             pred = preds_this_horizon[:, q]\n",
    "#             # Calculate coverage (percentage of actual values within prediction interval)\n",
    "#             within_interval = (actual <= pred) \n",
    "#             coverage = np.mean(within_interval) * 100\n",
    "            \n",
    "#             # Expected coverage for q\n",
    "#             expected_coverage = (quantile) * 100\n",
    "            \n",
    "#             coverage_stats[horizon][model_name][quantile] = {\n",
    "#                 'coverage': coverage,\n",
    "#                 'expected': expected_coverage,\n",
    "#                 'difference': coverage - expected_coverage\n",
    "#             }\n",
    "            \n",
    "#             print(f\"Horizon {horizon} - {model_name}:\")\n",
    "#             print(f\"  Actual coverage: {coverage:.1f}%\")\n",
    "#             print(f\"  Expected coverage: {expected_coverage:.1f}%\")\n",
    "#             print(f\"  Difference: {coverage - expected_coverage:+.1f}%\")\n",
    "\n",
    "#             # Plot coverage comparison for all quantiles \n",
    "#             fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "#             horizons = config['data']['horizons']\n",
    "#             quantiles = config['data']['quantiles']\n",
    "\n",
    "#             # Calculate positions for grouped bars\n",
    "#             n_quantiles = len(quantiles)\n",
    "#             n_horizons = len(horizons)\n",
    "#             x = np.arange(n_horizons)\n",
    "#             width = 0.35 / n_quantiles  # Adjust width based on number of quantiles\n",
    "\n",
    "#     # Prepare data for all quantiles\n",
    "#     for q_idx, quantile in enumerate(quantiles):\n",
    "#         fnn_coverage = [coverage_stats[h]['FNN'][quantile]['coverage'] for h in horizons]\n",
    "#         lqr_coverage = [coverage_stats[h]['LQR'][quantile]['coverage'] for h in horizons]\n",
    "#         expected_coverage = coverage_stats[horizons[0]]['FNN'][quantile]['expected']  # Same for all horizons\n",
    "        \n",
    "#         # Calculate bar positions\n",
    "#         fnn_pos = x - width/2 + q_idx * width * 2\n",
    "#         lqr_pos = x + width/2 + q_idx * width * 2\n",
    "        \n",
    "#         # Plot bars for this quantile\n",
    "#         bars1 = ax.bar(fnn_pos, fnn_coverage, width, \n",
    "#                         label=f'FNN Q{quantile:.2f}', alpha=0.8)\n",
    "#         bars2 = ax.bar(lqr_pos, lqr_coverage, width, \n",
    "#                         label=f'LQR Q{quantile:.2f}', alpha=0.8)\n",
    "        \n",
    "#         # Add expected coverage line for this quantile\n",
    "#         ax.axhline(y=expected_coverage, color='gray', linestyle='--', \n",
    "#                     alpha=0.7, linewidth=1)\n",
    "        \n",
    "#         # Add value labels on bars\n",
    "#         for bars in [bars1, bars2]:\n",
    "#             for bar in bars:\n",
    "#                 height = bar.get_height()\n",
    "#                 ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "#                         f'{height:.1f}%', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "#     ax.set_xlabel('Forecast Horizon')\n",
    "#     ax.set_ylabel('Coverage (%)')\n",
    "#     ax.set_title('Prediction Interval Coverage Analysis by Quantile')\n",
    "#     ax.set_xticks(x)\n",
    "#     ax.set_xticklabels([f'H{h}' for h in horizons])\n",
    "#     ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "#     ax.grid(True, alpha=0.3)\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "#     print(\"\\n✓ Forecast visualization completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c74291d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 8. Statistical Significance Testing ===\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"STATISTICAL SIGNIFICANCE TESTING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Generic function for comparing two models\n",
    "def compare_models_dm_test(model1_predictions, model2_predictions, targets, \n",
    "                          model1_name=\"Model1\", model2_name=\"Model2\", countries=None):\n",
    "    \"\"\"\n",
    "    Perform Diebold-Mariano test for forecast accuracy comparison between any two models.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model1_predictions : dict\n",
    "        Dictionary with country keys and prediction arrays\n",
    "    model2_predictions : dict  \n",
    "        Dictionary with country keys and prediction arrays\n",
    "    targets : dict\n",
    "        Dictionary with country keys and target arrays\n",
    "    model1_name : str\n",
    "        Name of first model for display\n",
    "    model2_name : str\n",
    "        Name of second model for display\n",
    "    countries : list\n",
    "        List of countries to compare (if None, use all available)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Results of DM tests per country and aggregate\n",
    "    \"\"\"\n",
    "    from scipy import stats\n",
    "    \n",
    "    if countries is None:\n",
    "        countries = list(model1_predictions.keys())\n",
    "    \n",
    "    dm_results_per_country = {}\n",
    "    dm_results_aggregate = {}\n",
    "\n",
    "    # Per-Country Diebold-Mariano Tests\n",
    "    for country in countries:\n",
    "        if (model1_predictions.get(country) is not None and \n",
    "            model2_predictions.get(country) is not None):\n",
    "            \n",
    "            dm_results_per_country[country] = {}\n",
    "            print(f\"\\n{country} - Diebold-Mariano Tests ({model1_name} vs {model2_name}):\")\n",
    "            \n",
    "            for h, horizon in enumerate(config['data']['horizons']):\n",
    "                dm_results_per_country[country][horizon] = {}\n",
    "                \n",
    "                for q, quantile in enumerate(config['data']['quantiles']):\n",
    "                    # Get targets for this country and horizon\n",
    "                    if targets[country].ndim == 2:\n",
    "                        actual = targets[country][:, h]\n",
    "                    else:\n",
    "                        actual = targets[country]\n",
    "                    \n",
    "                    # Get predictions for this country, horizon, and quantile\n",
    "                    model1_pred = model1_predictions[country][:, h][:, q]\n",
    "                    model2_pred = model2_predictions[country][:, h][:, q]\n",
    "                    \n",
    "                    if len(actual) > 5:  # Need minimum samples for meaningful test\n",
    "                        # Calculate quantile losses (more appropriate for quantile forecasting)\n",
    "                        model1_qloss = pinball_loss(actual, model1_pred, quantile)\n",
    "                        model2_qloss = pinball_loss(actual, model2_pred, quantile)\n",
    "                        \n",
    "                        # Diebold-Mariano test statistic\n",
    "                        # H0: Both forecasts have equal accuracy\n",
    "                        # H1: Forecasts have different accuracy\n",
    "                        loss_diff = model1_qloss - model2_qloss  # Positive means Model1 worse\n",
    "                        \n",
    "                        # Calculate test statistic\n",
    "                        mean_diff = np.mean(loss_diff)\n",
    "                        var_diff = np.var(loss_diff, ddof=1)\n",
    "                        \n",
    "                        if var_diff > 0:\n",
    "                            dm_stat = mean_diff / np.sqrt(var_diff / len(loss_diff))\n",
    "                            p_value = 2 * (1 - stats.norm.cdf(abs(dm_stat)))  # Two-tailed test\n",
    "                            \n",
    "                            dm_results_per_country[country][horizon][quantile] = {\n",
    "                                'dm_statistic': dm_stat,\n",
    "                                'p_value': p_value,\n",
    "                                'significant': p_value < 0.1,\n",
    "                                'better_model': model2_name if dm_stat > 0 else model1_name\n",
    "                            }\n",
    "                            \n",
    "                            significance = \"***\" if p_value < 0.01 else \"**\" if p_value < 0.05 else \"*\" if p_value < 0.1 else \"\"\n",
    "                            \n",
    "                            print(f\"  H{horizon} Q{quantile:.2f}: DM={dm_stat:.3f}, p={p_value:.3f}{significance} -> {dm_results_per_country[country][horizon][quantile]['better_model']}\")\n",
    "                        else:\n",
    "                            dm_results_per_country[country][horizon][quantile] = {\n",
    "                                'dm_statistic': 0,\n",
    "                                'p_value': 1.0,\n",
    "                                'significant': False,\n",
    "                                'better_model': 'Tie'\n",
    "                            }\n",
    "                            print(f\"  H{horizon} Q{quantile:.2f}: No variance in loss differences\")\n",
    "                    else:\n",
    "                        dm_results_per_country[country][horizon][quantile] = {\n",
    "                            'dm_statistic': np.nan,\n",
    "                            'p_value': np.nan,\n",
    "                            'significant': False,\n",
    "                            'better_model': 'Insufficient data'\n",
    "                        }\n",
    "                        print(f\"  H{horizon} Q{quantile:.2f}: Insufficient data for testing\")\n",
    "\n",
    "    return dm_results_per_country, dm_results_aggregate\n",
    "\n",
    "# Use the generic function to compare FNN vs LQR\n",
    "dm_results_per_country, dm_results_aggregate = compare_models_dm_test(\n",
    "    fnn_per_country_predictions, \n",
    "    lqr_per_country_predictions, \n",
    "    fnn_per_country_targets,\n",
    "    model1_name=\"FNN\",\n",
    "    model2_name=\"LQR\",\n",
    "    countries=countries\n",
    ")\n",
    "\n",
    "# Aggregate Diebold-Mariano Tests (for comparison)\n",
    "def compute_aggregate_dm_tests(model1_predictions, model2_predictions, targets, \n",
    "                              model1_name=\"Model1\", model2_name=\"Model2\", countries=None):\n",
    "    \"\"\"\n",
    "    Compute aggregate Diebold-Mariano tests across all countries for any two models.\n",
    "    \"\"\"\n",
    "    from scipy import stats\n",
    "    \n",
    "    if countries is None:\n",
    "        countries = list(model1_predictions.keys())\n",
    "    \n",
    "    dm_results_aggregate = {}\n",
    "    \n",
    "    print(f\"\\nAGGREGATE ANALYSIS - Diebold-Mariano Tests ({model1_name} vs {model2_name}):\")\n",
    "    for h, horizon in enumerate(config['data']['horizons']):\n",
    "        dm_results_aggregate[horizon] = {}\n",
    "        \n",
    "        for q, quantile in enumerate(config['data']['quantiles']):\n",
    "            # Aggregate data across all countries for this horizon and quantile\n",
    "            all_model1_losses = []\n",
    "            all_model2_losses = []\n",
    "            \n",
    "            for country in countries:\n",
    "                if (model1_predictions.get(country) is not None and \n",
    "                    model2_predictions.get(country) is not None):\n",
    "                    \n",
    "                    # Get targets for this country and horizon\n",
    "                    if targets[country].ndim == 2:\n",
    "                        actual = targets[country][:, h]\n",
    "                    else:\n",
    "                        actual = targets[country]\n",
    "                    \n",
    "                    # Get predictions for this country, horizon, and quantile\n",
    "                    model1_pred = model1_predictions[country][:, h][:, q]\n",
    "                    model2_pred = model2_predictions[country][:, h][:, q]\n",
    "                    \n",
    "                    # Calculate quantile losses\n",
    "                    model1_qloss = pinball_loss(actual, model1_pred, quantile)\n",
    "                    model2_qloss = pinball_loss(actual, model2_pred, quantile)\n",
    "                    \n",
    "                    all_model1_losses.extend(model1_qloss)\n",
    "                    all_model2_losses.extend(model2_qloss)\n",
    "            \n",
    "            if len(all_model1_losses) > 1:\n",
    "                # Convert to numpy arrays\n",
    "                all_model1_losses = np.array(all_model1_losses)\n",
    "                all_model2_losses = np.array(all_model2_losses)\n",
    "                \n",
    "                # Diebold-Mariano test statistic\n",
    "                loss_diff = all_model1_losses - all_model2_losses  # Positive means Model1 worse\n",
    "                \n",
    "                # Calculate test statistic\n",
    "                mean_diff = np.mean(loss_diff)\n",
    "                var_diff = np.var(loss_diff, ddof=1)\n",
    "                \n",
    "                if var_diff > 0:\n",
    "                    dm_stat = mean_diff / np.sqrt(var_diff / len(loss_diff))\n",
    "                    p_value = 2 * (1 - stats.norm.cdf(abs(dm_stat)))  # Two-tailed test\n",
    "                    \n",
    "                    dm_results_aggregate[horizon][quantile] = {\n",
    "                        'dm_statistic': dm_stat,\n",
    "                        'p_value': p_value,\n",
    "                        'significant': p_value < 0.1,\n",
    "                        'better_model': model2_name if dm_stat > 0 else model1_name\n",
    "                    }\n",
    "                    \n",
    "                    significance = \"***\" if p_value < 0.01 else \"**\" if p_value < 0.05 else \"*\" if p_value < 0.1 else \"\"\n",
    "                    \n",
    "                    print(f\"  H{horizon} Q{quantile:.2f}: DM={dm_stat:.3f}, p={p_value:.3f}{significance} -> {dm_results_aggregate[horizon][quantile]['better_model']}\")\n",
    "                else:\n",
    "                    print(f\"  H{horizon} Q{quantile:.2f}: No variance in loss differences\")\n",
    "            else:\n",
    "                print(f\"  H{horizon} Q{quantile:.2f}: Insufficient data for testing\")\n",
    "    \n",
    "    return dm_results_aggregate\n",
    "\n",
    "# Compute aggregate results for FNN vs LQR\n",
    "dm_results_aggregate = compute_aggregate_dm_tests(\n",
    "    fnn_per_country_predictions,\n",
    "    lqr_per_country_predictions, \n",
    "    fnn_per_country_targets,\n",
    "    model1_name=\"FNN\",\n",
    "    model2_name=\"LQR\",\n",
    "    countries=countries\n",
    ")\n",
    "\n",
    "# Create Diebold-Mariano summary table\n",
    "print(\"\\nDiebold-Mariano Test Results Summary:\")\n",
    "dm_summary_data = []\n",
    "\n",
    "for country in countries:\n",
    "    if country in dm_results_per_country:\n",
    "        for horizon in config['data']['horizons']:\n",
    "            for quantile in config['data']['quantiles']:\n",
    "                dm_result = dm_results_per_country[country][horizon][quantile]\n",
    "                dm_summary_data.append({\n",
    "                    'Country': country,\n",
    "                    'Horizon': horizon,\n",
    "                    'Quantile': quantile,\n",
    "                    'DM_Statistic': dm_result['dm_statistic'],\n",
    "                    'P_Value': dm_result['p_value'],\n",
    "                    'Significant': dm_result['significant'],\n",
    "                    'Better_Model': dm_result['better_model']\n",
    "                })\n",
    "\n",
    "dm_summary_df = pd.DataFrame(dm_summary_data)\n",
    "display(dm_summary_df.round(4))\n",
    "\n",
    "# === 9. Per-Country Quantile Loss Analysis ===\n",
    "print(\"\\n9. Computing per-country Quantile Loss metrics...\")\n",
    "\n",
    "# Generic function for per-country metrics comparison\n",
    "def compute_per_country_metrics(model1_predictions, model2_predictions, targets,\n",
    "                               model1_name=\"Model1\", model2_name=\"Model2\", countries=None):\n",
    "    \"\"\"\n",
    "    Calculate Quantile Loss for each country, quantile, and horizon for any two models.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model1_predictions : dict\n",
    "        Dictionary with country keys and prediction arrays\n",
    "    model2_predictions : dict  \n",
    "        Dictionary with country keys and prediction arrays\n",
    "    targets : dict\n",
    "        Dictionary with country keys and target arrays\n",
    "    model1_name : str\n",
    "        Name of first model for display\n",
    "    model2_name : str\n",
    "        Name of second model for display\n",
    "    countries : list\n",
    "        List of countries to analyze (if None, use all available)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Per-country metrics for each model\n",
    "    \"\"\"\n",
    "    if countries is None:\n",
    "        countries = list(model1_predictions.keys())\n",
    "    \n",
    "    per_country_metrics = {}\n",
    "\n",
    "    for country in countries:\n",
    "        if (model1_predictions.get(country) is not None and \n",
    "            model2_predictions.get(country) is not None):\n",
    "            \n",
    "            per_country_metrics[country] = {}\n",
    "            \n",
    "            for h, horizon in enumerate(config['data']['horizons']):\n",
    "                per_country_metrics[country][horizon] = {}\n",
    "                \n",
    "                # Get targets for this country and horizon\n",
    "                if targets[country].ndim == 2:\n",
    "                    actual = targets[country][:, h]\n",
    "                else:\n",
    "                    actual = targets[country]\n",
    "                \n",
    "                for q, quantile in enumerate(config['data']['quantiles']):\n",
    "                    per_country_metrics[country][horizon][quantile] = {}\n",
    "                    \n",
    "                    # Get predictions for this country, horizon, and quantile\n",
    "                    model1_pred = model1_predictions[country][:, h][:, q]\n",
    "                    model2_pred = model2_predictions[country][:, h][:, q]\n",
    "                    \n",
    "                    # Calculate Quantile Loss for each model\n",
    "                    for model_name, pred in [(model1_name, model1_pred), (model2_name, model2_pred)]:\n",
    "                        q_loss = np.mean(pinball_loss(actual, pred, quantile))\n",
    "                        per_country_metrics[country][horizon][quantile][model_name] = q_loss\n",
    "    \n",
    "    return per_country_metrics\n",
    "\n",
    "# Calculate metrics for FNN vs LQR\n",
    "per_country_metrics = compute_per_country_metrics(\n",
    "    fnn_per_country_predictions,\n",
    "    lqr_per_country_predictions,\n",
    "    fnn_per_country_targets,\n",
    "    model1_name=\"FNN\",\n",
    "    model2_name=\"LQR\", \n",
    "    countries=countries\n",
    ")\n",
    "\n",
    "# Create per-country metrics table and aggregate analysis\n",
    "def create_metrics_comparison_table(per_country_metrics, countries, \n",
    "                                   model1_name=\"Model1\", model2_name=\"Model2\"):\n",
    "    \"\"\"\n",
    "    Create comparison tables for any two models and compute aggregate metrics.\n",
    "    \"\"\"\n",
    "    # Create per-country metrics table\n",
    "    print(f\"\\nPer-Country Quantile Loss Performance ({model1_name} vs {model2_name}):\")\n",
    "    country_metrics_data = []\n",
    "\n",
    "    for country in countries:\n",
    "        if country in per_country_metrics:\n",
    "            for horizon in config['data']['horizons']:\n",
    "                for quantile in config['data']['quantiles']:\n",
    "                    model1_qloss = per_country_metrics[country][horizon][quantile][model1_name]\n",
    "                    model2_qloss = per_country_metrics[country][horizon][quantile][model2_name]\n",
    "                    improvement = ((model2_qloss - model1_qloss) / model2_qloss) * 100\n",
    "                    \n",
    "                    country_metrics_data.append({\n",
    "                        'Country': country,\n",
    "                        'Horizon': horizon,\n",
    "                        'Quantile': quantile,\n",
    "                        f'{model1_name}_QLoss': model1_qloss,\n",
    "                        f'{model2_name}_QLoss': model2_qloss,\n",
    "                        'Improvement_%': improvement,\n",
    "                        'Better_Model': model1_name if model1_qloss < model2_qloss else model2_name\n",
    "                    })\n",
    "\n",
    "    country_metrics_df = pd.DataFrame(country_metrics_data)\n",
    "    display(country_metrics_df.round(4))\n",
    "\n",
    "    # === Aggregate Summary ===\n",
    "    print(f\"\\nAggregate Quantile Loss Summary ({model1_name} vs {model2_name}):\")\n",
    "    aggregate_metrics_data = []\n",
    "\n",
    "    for horizon in config['data']['horizons']:\n",
    "        for quantile in config['data']['quantiles']:\n",
    "            # Aggregate across all countries\n",
    "            all_model1_qloss = []\n",
    "            all_model2_qloss = []\n",
    "            \n",
    "            for country in countries:\n",
    "                if country in per_country_metrics:\n",
    "                    all_model1_qloss.append(per_country_metrics[country][horizon][quantile][model1_name])\n",
    "                    all_model2_qloss.append(per_country_metrics[country][horizon][quantile][model2_name])\n",
    "            \n",
    "            avg_model1_qloss = np.mean(all_model1_qloss)\n",
    "            avg_model2_qloss = np.mean(all_model2_qloss)\n",
    "            improvement = ((avg_model2_qloss - avg_model1_qloss) / avg_model2_qloss) * 100\n",
    "            \n",
    "            aggregate_metrics_data.append({\n",
    "                'Horizon': horizon,\n",
    "                'Quantile': quantile,\n",
    "                f'{model1_name}_QLoss_Avg': avg_model1_qloss,\n",
    "                f'{model2_name}_QLoss_Avg': avg_model2_qloss,\n",
    "                'Improvement_%': improvement,\n",
    "                'Better_Model': model1_name if avg_model1_qloss < avg_model2_qloss else model2_name\n",
    "            })\n",
    "\n",
    "    aggregate_df = pd.DataFrame(aggregate_metrics_data)\n",
    "    print(\"\\nAggregate Performance Across All Countries:\")\n",
    "    display(aggregate_df.round(4))\n",
    "    \n",
    "    return country_metrics_df, aggregate_df\n",
    "\n",
    "# Generate tables for FNN vs LQR comparison\n",
    "country_metrics_df, aggregate_df = create_metrics_comparison_table(\n",
    "    per_country_metrics, countries, \n",
    "    model1_name=\"FNN\", model2_name=\"LQR\"\n",
    ")\n",
    "\n",
    "# === 10. Final Summary and Recommendations ===\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL QUANTILE LOSS EVALUATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def generate_final_summary(country_metrics_df, per_country_metrics, countries,\n",
    "                          model1_name=\"Model1\", model2_name=\"Model2\"):\n",
    "    \"\"\"\n",
    "    Generate final summary and recommendations for any two models comparison.\n",
    "    \"\"\"\n",
    "    # Calculate win rates for Quantile Loss only\n",
    "    qloss_win_summary = {\n",
    "        f'{model1_name}_wins': 0,\n",
    "        f'{model2_name}_wins': 0,\n",
    "        'total_comparisons': len(country_metrics_df)\n",
    "    }\n",
    "\n",
    "    for _, row in country_metrics_df.iterrows():\n",
    "        # Quantile Loss comparison\n",
    "        if row[f'{model1_name}_QLoss'] < row[f'{model2_name}_QLoss']:\n",
    "            qloss_win_summary[f'{model1_name}_wins'] += 1\n",
    "        else:\n",
    "            qloss_win_summary[f'{model2_name}_wins'] += 1\n",
    "\n",
    "    print(f\"\\nQuantile Loss Win Rate Summary ({model1_name} vs {model2_name}):\")\n",
    "    print(\"-\" * 50)\n",
    "    model1_wins = qloss_win_summary[f'{model1_name}_wins']\n",
    "    total = qloss_win_summary['total_comparisons']\n",
    "    model1_rate = (model1_wins / total) * 100\n",
    "\n",
    "    print(f\"Quantile Loss: {model1_name} wins {model1_wins}/{total} ({model1_rate:.1f}%)\")\n",
    "\n",
    "    # Country-by-Country Summary\n",
    "    print(f\"\\nCountry-by-Country Performance Summary ({model1_name} vs {model2_name}):\")\n",
    "    print(\"-\" * 60)\n",
    "    for country in countries:\n",
    "        if country in per_country_metrics:\n",
    "            country_data = country_metrics_df[country_metrics_df['Country'] == country]\n",
    "            country_model1_wins = sum(1 for _, row in country_data.iterrows() if row['Better_Model'] == model1_name)\n",
    "            country_total = len(country_data)\n",
    "            country_model1_rate = (country_model1_wins / country_total) * 100 if country_total > 0 else 0\n",
    "            \n",
    "            avg_improvement = country_data['Improvement_%'].mean()\n",
    "            \n",
    "            print(f\"{country}: {model1_name} wins {country_model1_wins}/{country_total} ({country_model1_rate:.1f}%) | \"\n",
    "                  f\"Avg improvement: {avg_improvement:+.2f}%\")\n",
    "\n",
    "    # Overall recommendation\n",
    "    if model1_rate > 60:\n",
    "        recommendation = f\"{model1_name} shows superior quantile forecasting performance\"\n",
    "    elif model1_rate < 40:\n",
    "        recommendation = f\"{model2_name} shows superior quantile forecasting performance\"\n",
    "    else:\n",
    "        recommendation = f\"Both {model1_name} and {model2_name} show comparable quantile forecasting performance\"\n",
    "\n",
    "    print(f\"\\nOverall Recommendation: {recommendation}\")\n",
    "\n",
    "    # Best and worst performing quantiles and horizons\n",
    "    print(f\"\\nPerformance by Quantile and Horizon ({model1_name} vs {model2_name}):\")\n",
    "    print(\"-\" * 50)\n",
    "    for horizon in config['data']['horizons']:\n",
    "        print(f\"\\nHorizon {horizon}:\")\n",
    "        for quantile in config['data']['quantiles']:\n",
    "            horizon_quantile_data = aggregate_df[\n",
    "                (aggregate_df['Horizon'] == horizon) & \n",
    "                (aggregate_df['Quantile'] == quantile)\n",
    "            ]\n",
    "            if not horizon_quantile_data.empty:\n",
    "                row = horizon_quantile_data.iloc[0]\n",
    "                print(f\"  Quantile {quantile:.2f}: {row['Better_Model']} wins | \"\n",
    "                      f\"Improvement: {row['Improvement_%']:+.2f}%\")\n",
    "\n",
    "    print(f\"\\nKey Insights:\")\n",
    "    print(\"• Quantile Loss is the most relevant metric for quantile forecasting evaluation\")\n",
    "    print(\"• Per-country analysis reveals model performance heterogeneity across countries\")\n",
    "    print(\"• Different quantiles may have varying predictability across forecast horizons\")\n",
    "    print(\"• Country-specific characteristics may favor different modeling approaches\")\n",
    "\n",
    "    print(f\"\\n✓ Complete per-country quantile loss evaluation finished ({model1_name} vs {model2_name})!\")\n",
    "\n",
    "# Generate summary for FNN vs LQR\n",
    "generate_final_summary(country_metrics_df, per_country_metrics, countries,\n",
    "                      model1_name=\"FNN\", model2_name=\"LQR\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
